{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Jeevan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = pd.read_csv('twitter_cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hate': 144, 'war': 94, 'murder': 92, 'stupid': 84, 'bitch': 83, 'rape': 76, 'shit': 75, 'fuck': 73, 'hatred': 61, 'bad': 59, 'dumb': 56, 'slavery': 56, 'murdered': 52, 'terrorist': 51, 'murdering': 43, 'killed': 41, 'idiot': 39, 'terrorists': 37, 'death': 35, 'kill': 34, 'ass': 33, 'violence': 32, 'raped': 31, 'abuse': 30, 'lying': 29, 'liar': 28, 'racist': 28, 'vile': 22, 'terrorism': 22, 'killing': 22, 'raping': 21, 'sick': 21, 'violent': 21, 'bitches': 21, 'hell': 19, 'evil': 18, 'dead': 17, 'worst': 16, 'nasty': 16, 'murderer': 15, 'rapist': 15, 'robber': 14, 'horrible': 13, 'terror': 12, 'destroy': 12, 'disgusting': 12, 'bitchy': 12, 'ugly': 12, 'die': 11, 'hating': 11, 'fraud': 11, 'dick': 11, 'racism': 10, 'criminal': 10, 'prison': 10, 'slut': 10, 'insult': 9, 'wtf': 9, 'rapists': 9, 'cunts': 9, 'murderous': 8, 'murders': 8, 'destruction': 8, 'murderers': 8, 'illegal': 8, 'crime': 8, 'bullshit': 8, 'fucked': 8, 'cancer': 7, 'whore': 7, 'assholes': 7, 'hurt': 7, 'died': 7, 'threat': 7, 'fired': 7, 'hated': 7, 'sluts': 7, 'idiotic': 6, 'retarded': 6, 'liars': 6, 'rob': 6, 'brutal': 6, 'killings': 6, 'ban': 6, 'enslave': 6, 'conspiracy': 6, 'criminals': 6, 'assault': 6, 'fascist': 5, 'racists': 5, 'rejected': 5, 'angry': 5, 'killer': 5, 'fail': 5, 'pathetic': 5, 'torture': 4, 'moronic': 4, 'failed': 4, 'insulted': 4, 'scumbag': 4, 'wicked': 4, 'choke': 4, 'whores': 3, 'suicide': 3, 'perverted': 3, 'stealing': 3, 'killers': 3, 'fucker': 3, 'kills': 3, 'rapes': 3, 'abused': 3, 'stab': 3, 'destroys': 3, 'rage': 3, 'threatening': 3, 'rotten': 3, 'twat': 3, 'dumbass': 3, 'assaulted': 3, 'ffs': 3, 'pain': 3, 'failing': 3, 'danger': 2, 'curse': 2, 'poverty': 2, 'frauds': 2, 'stupider': 2, 'brutalize': 2, 'brutality': 2, 'destructive': 2, 'devil': 2, 'pissed': 2, 'abhorrent': 2, 'prisoners': 2, 'punish': 2, 'pervert': 2, 'crisis': 2, 'destroying': 2, 'tortured': 2, 'enemy': 2, 'virulent': 2, 'puke': 2, 'faggot': 2, 'dishonest': 2, 'douchebag': 2, 'ruin': 2, 'dumbest': 2, 'outrage': 2, 'wars': 2, 'negative': 2, 'prejudice': 2, 'abandonment': 2, 'scandalous': 2, 'degrading': 2, 'suckers': 2, 'terrifying': 2, 'harassment': 2, 'loser': 2, 'outraged': 2, 'abusive': 2, 'steals': 1, 'savages': 1, 'failure': 1, 'terrorizing': 1, 'prisoner': 1, 'furious': 1, 'nigger': 1, 'brutalizing': 1, 'molesting': 1, 'negativity': 1, 'shithead': 1, 'misery': 1, 'abuses': 1, 'totalitarianism': 1, 'offending': 1, 'cruel': 1, 'disaster': 1, 'indignation': 1, 'fuckers': 1, 'victimize': 1, 'injustice': 1, 'cocksucker': 1, 'spite': 1, 'suffer': 1, 'fatal': 1, 'riot': 1, 'disgust': 1, 'nastier': 1, 'violated': 1, 'panic': 1, 'horrors': 1, 'poison': 1, 'revenge': 1, 'shitty': 1, 'disgusted': 1, 'po': 1, 'faggots': 1, 'horrendous': 1, 'poisoning': 1, 'wanker': 1, 'horror': 1, 'villain': 1, 'anger': 1, 'abusers': 1, 'contempt': 1, 'sadder': 1, 'insanity': 1, 'terrified': 1, 'harassed': 1, 'violating': 1, 'sabotage': 1, 'arrogance': 1, 'horrifically': 1, 'horrid': 1, 'painfully': 1, 'depressed': 1}\n"
     ]
    }
   ],
   "source": [
    "# Convert column to string and drop NaN values\n",
    "twitter_data['cleaned_text'] = twitter_data['cleaned_text'].astype(str).fillna('')\n",
    "\n",
    "# Tokenize words and clean text\n",
    "words = [word.lower() for text in twitter_data['cleaned_text'] for word in re.findall(r'\\b\\w+\\b', str(text))]\n",
    "\n",
    "# Count word frequency\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Initialize Sentiment Analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analyze sentiment of each word and keep only harmful ones\n",
    "harmful_words = {word: count for word, count in word_counts.items() if sia.polarity_scores(word)['compound'] < -0.5}\n",
    "\n",
    "# Sort by frequency\n",
    "sorted_harmful_words = dict(sorted(harmful_words.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Display top harmful words\n",
    "print(sorted_harmful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Word Defense - Stop Cyberbullying!\n",
      "\n",
      "\n",
      "Sentence: Nobody likes a whore person.\n",
      "Great job! Using kinder words fosters a healthier online environment.\n",
      "\n",
      "Sentence: Nobody likes a bitch person.\n",
      "Great job! Using kinder words fosters a healthier online environment.\n",
      "\n",
      "Sentence: Stop being so terrorist all the time.\n",
      "Great job! Using kinder words fosters a healthier online environment.\n",
      "\n",
      "Sentence: You are such a racist!\n",
      "Try again! A better word choice can make a difference.\n",
      "\n",
      "Sentence: Stop being so stupid all the time.\n",
      "Try again! A better word choice can make a difference.\n",
      "\n",
      "Game Over! Your final score: 30\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def load_harmful_words():\n",
    "    \"\"\"Load harmful words from a predefined dataset.\"\"\"\n",
    "    return [\"sexist\", \"racist\", \"terrorist\", \"slut\", \"whore\", \"bitch\", \"idiot\", \"stupid\", \"hate\"]\n",
    "\n",
    "def generate_sentence(harmful_words):\n",
    "    \"\"\"Generate a sample sentence containing a harmful word.\"\"\"\n",
    "    templates = [\n",
    "        \"You are such a {}!\",\n",
    "        \"Stop being so {} all the time.\",\n",
    "        \"Nobody likes a {} person.\",\n",
    "        \"That was a very {} thing to say.\"\n",
    "    ]\n",
    "    word = random.choice(harmful_words)\n",
    "    sentence = random.choice(templates).format(word)\n",
    "    return sentence, word\n",
    "\n",
    "def play_game():\n",
    "    \"\"\"Main function to play the game.\"\"\"\n",
    "    harmful_words = load_harmful_words()\n",
    "    score = 0\n",
    "    rounds = 5\n",
    "    \n",
    "    print(\"Welcome to Word Defense - Stop Cyberbullying!\\n\")\n",
    "    \n",
    "    for _ in range(rounds):\n",
    "        sentence, word = generate_sentence(harmful_words)\n",
    "        print(f\"\\nSentence: {sentence}\")\n",
    "        replacement = input(\"Replace the harmful word with a positive alternative: \").strip()\n",
    "        \n",
    "        if replacement and replacement.lower() != word.lower():\n",
    "            print(\"Great job! Using kinder words fosters a healthier online environment.\")\n",
    "            score += 10\n",
    "        else:\n",
    "            print(\"Try again! A better word choice can make a difference.\")\n",
    "        \n",
    "    print(f\"\\nGame Over! Your final score: {score}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
